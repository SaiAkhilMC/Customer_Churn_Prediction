# -*- coding: utf-8 -*-
"""CustomerChurnPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fnIX_C5uWF48QemJjuKHeoT47PpaP9nT
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

data=pd.read_csv('/content/drive/MyDrive/Customer-Churn-Prediction.csv')
data

data.shape

data.isnull().sum()

data=data.drop('customerID',axis=1)

data

data['Churn'].value_counts()

sns.countplot(x='Churn',data=data)

sns.countplot(x='gender',hue='Churn',data=data)

data.dtypes

data=data.drop(columns=['gender','PhoneService','MultipleLines','InternetService','StreamingTV','StreamingMovies'],axis=1)

print(data['TotalCharges'].dtypes)

data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')

data=data.dropna(subset=['TotalCharges'])

print(data['TotalCharges'].dtypes)

data.isnull().sum()

data=pd.get_dummies(data,columns=['SeniorCitizen','Partner','Dependents','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','Contract','PaperlessBilling','PaymentMethod'])

data['Churn']=data['Churn'].replace({'Yes':1,'No':0})

from sklearn.preprocessing import LabelEncoder

lb=LabelEncoder()

plt.boxplot(data[['tenure','MonthlyCharges']])

from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import chi2
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

X=data.drop('Churn',axis=1)
X

y=data['Churn']
y

select=SelectKBest(chi2)

select.fit(X,y)

select.scores_

score_col=pd.DataFrame({'Scores':select.scores_})

col=pd.DataFrame({'Columns':X.columns})
col

score_data=pd.concat([col,score_col],axis=1)
score_data

select_new=SelectKBest(score_func=f_classif)

select_new.fit(X,y)

scor_col1=select_new.scores_

score_col_1=pd.DataFrame({'Scores':scor_col1})

score_data_1=pd.concat([col,score_col_1],axis=1)

score_data_1

x=StandardScaler().fit_transform(X)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=7)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

from sklearn.linear_model import LogisticRegression
logmodel = LogisticRegression()

logmodel.fit(X_train,y_train)

logmodel.score(X_test,y_test)

log_pred = logmodel.predict(X_test)

from sklearn import metrics
cm=metrics.confusion_matrix(y_test, log_pred, labels=[1, 0])
df_cm = pd.DataFrame(cm, index = [i for i in ["Actual 1","Actual 0"]],
columns = [i for i in ["Predict 1","Predict 0"]])
plt.title('\nLogistic Regression Confusion Matrix')
sns.heatmap(df_cm, annot=True, fmt='g');

TP = cm[0,0]
FP = cm[0,1]
FN = cm[1,0]
TN = cm[1,1]

classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)
print('\nClassification accuracy: {0:0.4f}'.format(classification_accuracy))